"""
A lot of this is inspired by the concise and simple article found here:
https://towardsdatascience.com/generating-pok%C3%A9mon-names-using-rnns-f41003143333
"""

# All the modelling stuff
from keras.callbacks import LambdaCallback
from keras.layers import Dense, LSTM, TimeDistributed, LayerNormalization
from keras import Sequential
import numpy as np
import pickle

# This can be changed to names, greek or latin with the current setup
from generate_data import greek as corpus


def one_hot_encode_dict(text_list: list) -> (dict, dict):
    """
    Takes a list of strings and outputs a dictionary to one hot encode that set for
    the upcoming RNN

    :param text_list: list, a list of strings for one-hot-encoding
    :return: tuple, two dictionaries to perform one-hot-encoding and decoding
    """
    # form the set of all characters in the corpus
    s = set()
    for text in text_list:
        s |= set(text)

    # make the one-hot-encoding
    encoder = {char: i for i, char in enumerate(s)}
    decoder = {encoder[key]: key for key in encoder}
    return encoder, decoder


def encode_corpus(text_list: list) -> (np.array, np.array, dict, dict):
    """
    Take a corpus, create a one-hot-encoding and spit out inputs X, outputs Y,
    and both encoding and decoding dictionaries

    :param text_list: list, the corpus
    :return: (np.array, np.array, dict, dict),
    """
    # For one hot encoding
    encoder, decoder = one_hot_encode_dict(text_list)

    # init inputs X and outputs Y
    X = np.zeros((m, max_char, len(encoder)))
    Y = np.zeros((m, max_char, len(decoder)))

    # Convert corpus into sequential information
    for i in range(m):
        text = list(text_list[i])
        for j in range(len(text)):
            X[i, j, encoder[text[j]]] = 1
            if j < len(text) - 1:
                Y[i, j, encoder[text[j+1]]] = 1

    return X, Y, encoder, decoder


def make_name(mdl, prompt: str = '') -> str:
    """
    Takes a model mdl and a prompt (default is empty) and returns text generated by the model

    :param mdl: keras.Sequential(), a ML model
    :param prompt: str, a string to prompt the RNN
    :return: str, a string generated by the RNN
    """
    generated_text = []
    x = np.zeros((1, max_char, char_dim))
    end = False
    i = 0

    for char in prompt:
        x[0, i + 1, char_to_index[char]] = 1
        generated_text.append(char)
        i += 1

    while not end:
        probs = list(mdl.predict(x)[0, i])
        probs = probs / np.sum(probs)
        index = np.random.choice(range(char_dim), p=probs)
        if i == max_char - 2:
            character = '.'
            end = True
        else:
            character = index_to_char[index]
        generated_text.append(character)
        x[0, i + 1, index] = 1
        i += 1
        if generated_text.count('.') == 2:
            end = True

    print(''.join(generated_text))


def generate_name_loop(epoch, _):
    if epoch % 100 == 0:

        print(f'Text generated after epoch {epoch}:')

        for i in range(3):
            make_name(model)

        print()


def generate_loss(epoch, _):
    if epoch % 100 == 0:
        model.fit(X, Y)
        print()


name_generator = LambdaCallback(on_epoch_end=generate_name_loop)
loss = LambdaCallback(on_epoch_end=generate_loss)

if __name__ == "__main__":
    # Some variables we need to be global
    m = len(corpus)
    max_char = len(max(corpus, key=len))
    X, Y, char_to_index, index_to_char = encode_corpus(corpus)
    char_dim = len(char_to_index)

    metadata_file = 'obj/metadata'

    pickle.dump(
        {
            'max_char': max_char,
            'char_dim': char_dim,
            'encoder': char_to_index,
            'decoder': index_to_char
        },
        open(metadata_file, 'wb'),
        pickle.HIGHEST_PROTOCOL
    )

    print(f"Metadata saved to {metadata_file}.")

    # Define model
    model = Sequential()
    model.add(LSTM(128, input_shape=(max_char, char_dim), return_sequences=True))
    model.add(TimeDistributed(LayerNormalization()))
    model.add(TimeDistributed(Dense(char_dim, activation='softmax')))
    model.compile(loss='categorical_crossentropy', optimizer='adam')

    # train model
    model.fit(X, Y, batch_size=64, epochs=1500, callbacks=[name_generator, loss], verbose=0)

    import random

    try:
        while True:
            prompt = input("Prompt for the model:\n").lower()
            m = int((len(prompt) - 2) / 3 + 2) if len(prompt) >= 3 else 0
            if prompt == 'exit':
                print("Thanks for playing!")
                break
            elif prompt != '':
                prompt += ' '
            print('\n' + '*' * 10 + '\n')
            for _ in range(5):
                r = random.randint(1, m) if m else 0
                print(make_name(model, prompt[:-r]))
            print('\n' + '*' * 10 + '\n')
    except KeyboardInterrupt:
        print("Thanks for playing!")